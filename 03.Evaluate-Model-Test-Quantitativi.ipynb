{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline \nimport json\n\ndef calculate_top_k_predictions(results, top_k_values=[1, 10, 50]):\n    \"\"\"\n    Calcola le predizioni corrette per ciascun modello nelle categorie:\n    - Top 1\n    - Top 10\n    - Top 50\n    - Non in Top 50\n    \n    Args:\n    - results: Lista di dizionari con chiavi:\n        - `gold_token`: Il token corretto\n        - `predicted_tokens`: Lista dei token predetti in ordine di probabilitÃ \n    - top_k_values: Lista dei valori di Top-k da analizzare (default: [1, 10, 50])\n\n    Returns:\n    - metrics: Dizionario con i conteggi per ogni categoria\n    \"\"\"\n    metrics = {\n        \"top_1\": 0,\n        \"top_10\": 0,\n        \"top_50\": 0,\n        \"not_in_top_50\": 0\n    }\n    \n    for result in results:\n        gold_token = result[\"correct_token\"]\n        predicted_tokens = result[\"predicted_tokens\"]\n        \n        # Determina la categoria del gold token\n        if gold_token == predicted_tokens[0]:\n            metrics[\"top_1\"] += 1\n        elif gold_token in predicted_tokens[:top_k_values[1]]:\n            metrics[\"top_10\"] += 1\n        elif gold_token in predicted_tokens[:top_k_values[2]]:\n            metrics[\"top_50\"] += 1\n        else:\n            metrics[\"not_in_top_50\"] += 1\n\n    return metrics\n\n\ndef convert_to_percentages(metrics, total):\n    \"\"\"\n    Converte i conteggi delle metriche in percentuali.\n\n    Args:\n    - metrics: Dizionario con i conteggi delle metriche.\n    - total: Numero totale di frasi.\n\n    Returns:\n    - metrics_percent: Dizionario con le percentuali per ogni categoria.\n    \"\"\"\n    metrics_percent = {\n        key: (value / total) * 100 if total > 0 else 0 for key, value in metrics.items()\n    }\n    return metrics_percent\n\n\ndef evaluate_models(models, test_data, top_k_values=[1, 10, 50]):\n    \"\"\"\n    Esegue le predizioni per ogni modello e calcola le metriche Top-k.\n\n    Args:\n    - models: Dizionario di pipeline fill-mask {nome_modello: pipeline_fillmask}.\n    - test_data: Lista di dizionari con chiavi:\n        - `masked_sentence`: Frase con <mask>\n        - `gold_token`: Token corretto\n    - top_k_values: Lista dei valori di Top-k da analizzare (default: [1, 10, 50])\n\n    Returns:\n    - summary: Dizionario con metriche aggregate per ciascun modello\n    \"\"\"\n    summary = {}\n    total_sentences = len(test_data)\n    \n    for model_name, fillmask_pipeline in models.items():\n        print(f\"Eseguendo predizioni per il modello: {model_name}\")\n        results = []\n        for entry in test_data:\n            masked_sent = entry[\"masked_sentence\"]\n            if model_name == 'LatinBERT':\n                masked_sent = masked_sent.replace(\"<mask>\", \"[MASK]\")\n            gold_token = entry[\"correct_token\"]\n\n            # Predizioni del modello\n            predictions = fillmask_pipeline(masked_sent, top_k=max(top_k_values))\n            predicted_tokens = [pred[\"token_str\"].strip().replace(\" \", \"\") for pred in predictions]\n\n            # Salva il risultato\n            results.append({\n                \"correct_token\": gold_token,\n                \"predicted_tokens\": predicted_tokens\n            })\n\n        # Calcola le metriche per il modello corrente\n        metrics = calculate_top_k_predictions(results, top_k_values=top_k_values)\n        metrics_percent = convert_to_percentages(metrics, total_sentences)\n        summary[model_name] = metrics_percent\n\n    return summary\n\n\n\n# Modelli da valutare\nmodel_xlmr = \"Cicciokr/XLM-Roberta-Base-Latin-Uncased\"\nmodel_roberta = \"Cicciokr/Roberta-Base-Latin-Uncased\"\nmodel_latinbert = \"/kaggle/input/bert-base-latin-uncased/transformers/default/1\"\nmodel_latincybert = \"latincy/latinbert2\"\n\n# Crea le pipeline fill-mask per i modelli\nmodels = {\n    \"XLM-RoBERTa\": pipeline(\"fill-mask\", model=model_xlmr, tokenizer=model_xlmr),\n    \"RoBERTa\": pipeline(\"fill-mask\", model=model_roberta, tokenizer=model_roberta),\n    \"LatinBERT\": pipeline(\"fill-mask\", model=model_latinbert, tokenizer=model_latinbert)\n}\n\n    # Dataset di test\nwith open(\"/kaggle/input/the-latin-library/test_data_latinlibrary.json\", \"r\", encoding=\"utf-8\") as f:\n    test_data = json.load(f)\n\n# Esegue la valutazione\nsummary = evaluate_models(models, test_data)\n\n# Stampa i risultati\nprint(\"\\n=== Risultati delle Metriche ===\")\nfor model_name, metrics in summary.items():\n    print(f\"\\nModello: {model_name}\")\n    for metric, value in metrics.items():\n        print(f\"  {metric}: {value}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T21:05:35.926318Z","iopub.execute_input":"2025-01-22T21:05:35.926717Z","iopub.status.idle":"2025-01-22T21:06:07.337967Z","shell.execute_reply.started":"2025-01-22T21:05:35.926689Z","shell.execute_reply":"2025-01-22T21:06:07.336850Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\nDevice set to use cpu\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Eseguendo predizioni per il modello: XLM-RoBERTa\nEseguendo predizioni per il modello: RoBERTa\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (131 > 50). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Eseguendo predizioni per il modello: LatinBERT\n\n=== Risultati delle Metriche ===\n\nModello: XLM-RoBERTa\n  top_1: 10\n  top_10: 16\n  top_50: 2\n  not_in_top_50: 21\n\nModello: RoBERTa\n  top_1: 18\n  top_10: 15\n  top_50: 3\n  not_in_top_50: 13\n\nModello: LatinBERT\n  top_1: 18\n  top_10: 15\n  top_50: 3\n  not_in_top_50: 13\n","output_type":"stream"}],"execution_count":8}]}
